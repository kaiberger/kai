
@InProceedings{RBL+10,
  Title                    = {{Caroline: An Autonomously Driving Vehicle for Urban Environments}},
  Author                   = {Rauskolb, Fred W. and Berger, Kai and Lipski, Christian and Magnor, Marcus and Cornelsen, Karsten and Effertz, Jan and Form, Thomas and Graefe, Fabian and Ohl, Sebastian and Schumacher, Walter and Wille, J\"{o}rn-Marten and Hecker, Peter and Nothdurft, Tobias and Doering, Michael and Homeier, Kai and Morgenroth, Johannes and Wolf, Lars and Basarke, Christian and Berger, Christian and G\"{u}lke, Tim and Klose, Felix and Rumpe, Bernhard},
  Booktitle                = {The DARPA Urban Challenge},
  Year                     = {2009},

  Address                  = {Berlin Heidelberg},
  Editor                   = {Buehler, Martin and Iagnemma, Karl and Singh, Sanjiv},
  Month                    = nov,
  Pages                    = {441--508},
  Publisher                = {Springer-Verlag},

  Abstract                 = {The 2007 DARPA Urban Challenge afforded the golden opportunity for the Technische Universitaet Braunschweig to demonstrate its abilities to develop an autonomously driving vehicle to compete with the world's best competitors. After several stages of qualification, our team CarOLO qualified early for the DARPA Urban Challenge Final Event and was among only eleven teams from initially 89 competitors to compete in the final. We had the ability to work together in a large group of experts, each contributing his expertise in his discipline, and significant organisational, financial and technical support by local sponsors who helped us to become the best non-US team. In this report, we describe the 2007 DARPA Urban Challenge, our contribution "Caroline", the technology and algorithms along with her performance in the DARPA Urban Challenge Final Event on November 3, 2007.},
  Doi                      = {10.1007/978-3-642-03991-1\_11},
  File                     = {:RelatedWork/2009 - Rauskolb et al. - Caroline An Autonomously Driving Vehicle for Urban Environments.pdf:pdf},
  keywords                 = {EN,MINE,bookchapter,reviewed},
  Url                      = {https://arxiv.org/pdf/1409.6584}
}

@inproceedings{LSB+08,
  title={A fast and robust approach to lane marking detection and lane tracking},
  author={Lipski, Christian and Scholz, Bj\"{o}rn and Berger, Kai and Linz, Christian and Stich, Timo and Magnor, Marcus},
  booktitle={IEEE Southwest Symposium on Image Analysis and Interpretation (SSIAI)},
  abstract={We present a lane detection algorithm that robustly detects and tracks various lane markings in real-time. The first part is a feature detection algorithm that transforms several input images into a top view perspective and analyzes local histograms. For this part we make use of state-of-the-art graphics hardware. The second part fits a very simple and flexible lane model to these lane marking features. The algorithm was thoroughly tested on an autonomous vehicle that was one of the finalists in the 2007 DARPA Urban Challenge. In combination with other sensors, i.e. a lidar, radar and vision based obstacle detection and surface classification, the autonomous vehicle is able to drive in an urban scenario at up to 15 mp/h.},
  pages={57--60},
  year={2008},
  keywords={MINE,EN,conference,reviewed},
  url={http://ieeexplore.ieee.org/document/4512284/},
  organization={IEEE}
}

@inproceedings{LLB+10,
  title={Virtual Video Camera: Image-Based Viewpoint Navigation Through Space and Time},
  author={Lipski, Christian and Linz, Christian and Berger, Kai and Sellent, Anita and Magnor, Marcus},
  booktitle={Computer Graphics Forum},
  volume={29},
  number={8},
  pages={2555--2568},
  year={2010},
  keywords={MINE,EN,conference,reviewed},
  abstract={We present an image-based rendering system to viewpoint-navigate through space and time of complex real-world, dynamic scenes. Our approach accepts unsynchronized, uncalibrated multivideo footage as input. Inexpensive, consumer-grade camcorders suffice to acquire arbitrary scenes, for example in the outdoors, without elaborate recording setup procedures, allowing also for hand-held recordings. Instead of scene depth estimation, layer segmentation or 3D reconstruction, our approach is based on dense image correspondences, treating view interpolation uniformly in space and time: spatial viewpoint navigation, slow motion or freeze-and-rotate effects can all be created in the same way. Acquisition simplification, integration of moving cameras, generalization to difficult scenes and space-time symmetric interpolation amount to a widely applicable virtual video camera system.},
  url={http://onlinelibrary.wiley.com/doi/10.1111/j.1467-8659.2010.01824.x/pdf},
  organization={Wiley Online Library}
}

@inproceedings{BRS+11,
  title={Markerless motion capture using multiple color-depth sensors},
  author={Berger, Kai and Ruhl, Kai and Schroeder, Yannic and Bruemmer, Christian and Scholz, Alexander and Magnor, Marcus},
  abstract={With the advent of the Microsoft Kinect, renewed focus has been put on monocular depth-based motion capturing. However, this approach is limited in that an actor has to move facing the camera. Due to the active light nature of the sensor, no more than one device has been used for motion capturing so far. In effect, any pose estimation must fail for poses occluded to the depth camera. Our work investigates on reducing or mitigating the detrimental effects of multiple active light emitters, thereby allowing motion capture from all angles. We systematically evaluate the concurrent use of one to four Kinects, including calibration, error measures and analysis, and present a time-multiplexing approach.},
  booktitle={VMV},
  pages={317--324},
  keywords={MINE,EN,conference,reviewed},
  year={2011},
  url={http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.207.9939&rep=rep1&type=pdf}
}

@article{SSB+11,
  title={Multiple kinect studies},
  author={Schr\"{o}der, Yannic and Scholz, Alexander and Berger, Kai and Ruhl, Kai and Guthe, Stefan and Magnor, Marcus},
  abstract={This project investigates multi-camera setups using Microsoft Kinects. Active structured light from the Kinect is used in several scenarious, including gas flow description, motion capture and free-viewpoint video. While the ability to capture depth alongside color data (RGB-D) is the starting point of the investigations, the structured light is also used more directly. In order to combine Kinects with passive recording approaches, common calibration with HD cameras is also a topic.},
  journal={Computer Graphics},
  volume={2},
  number={4},
  pages={6},
  keywords={MINE,EN,techreport,reviewed},
  url={https://pdfs.semanticscholar.org/8b58/fce6a54b76ffa1f571d184ec558364c0740e.pdf},
  year={2011}
}

@inproceedings{BLL+08,
  title={The area processing unit of Caroline-Finding the way through DARPA's Urban Challenge},
  author={Berger, Kai and Lipski, Christian and Linz, Christian and Stich, Timo and Magnor, Marcus},
  booktitle={International Workshop on Robot Vision},
  abstract={This paper presents a vision-based color segmentation algorithm suitable for urban environments that separates an image into areas of drivable and non-drivable terrain. Assuming that a part of the image is known to be drivable terrain, other parts of the image are classified by comparing the Euclidean distance of each pixel's color to the mean colors of the drivable area in real-time. Moving the search area depending on each frame's result ensures temporal consistency and coherence. Furthermore, the algorithm classifies artifacts such as white and yellow lane markings and hard shadows as areas of unknown drivability. The algorithm was thoroughly tested on the autonomous vehicle 'Caroline', which was a finalist in the 2007 DARPA Urban Challenge.},
  pages={260--274},
  year={2008},
  keywords={MINE,EN,conference,reviewed},
  organization={Springer, Berlin, Heidelberg},
  url={https://pdfs.semanticscholar.org/4b9d/b808c06635b784ce6c1409603c0487bcd684.pdf}
}

@article{BBB+08,
  title={Team CarOLO--Technical Paper},
  author={Basarke, Christian and Berger, Christian and Berger, Kai and Cornelsen, Karsten and Doering, Michael and Effertz, Jan and Form, Thomas and G\"{u}lke, Tim and Graefe, Fabian and Hecker, Peter and others},
  journal={Technische Universit\"{a}t Braunschweig, Braunschweig, Germany, Informatik-Bericht},
  volume={7},
  keywords={MINE,EN,techreport,reviewed},
  year={2008}
}

@inproceedings{BIA+09,
  title={Tomographic 4D Reconstruction of Gas Flows in the Presence of Occluders},
  author={Berger, Kai and Ihrke, Ivo and Atcheson, Bradley and Heidrich, Wolfgang and Magnor, Marcus A and others},
  abstract={We present a method that allows for reconstructing non-stationary, time-varying gas flows around moving objects. Our work extends the background oriented Schlieren tomography (3D-BOS) acquisition technique to capture gas flows also in the presence of occluding objects. An algorithm is presented that exploits the unique properties of BOS background patterns to robustly segment occluding objects. Numerical issues in the refractive index field reconstruction are addressed and successfully solved by the new method.},
  booktitle={VMV},
  pages={29--36},
  keywords={MINE,EN,conference,reviewed},
  url={https://pdfs.semanticscholar.org/15ea/77d4a88cccc0bb4a43e68e53084fa7ead1c9.pdf},
  year={2009}
}

@inproceedings{BLL+10a,
  title={A ghosting artifact detector for interpolated image quality assessment},
  author={Berger, Kai and Lipski, Christian and Linz, Christian and Sellent, Anita and Magnor, Marcus},
  abstract={We present a no-reference image quality metric for image interpolation. The approach is capable of detecting blurry regions as well as ghosting artifacts, e.g., in image based rendering scenarios. Based on the assumption that ghosting artifacts can be detected locally, perceived visual quality can be predicted from the amount of regions that are affected by ghosting. Because the approach does not require any reference image, it is very suitable, e.g., for assessing quality of image-based rendering techniques in general settings.},
  booktitle={IEEE 14th International Symposium on Consumer Electronics (ISCE)},
  pages={1--6},
  year={2010},
  keywords={MINE,EN,conference,reviewed},
  url={http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.167.1659&rep=rep1&type=pdf},
  organization={IEEE}
}

@article{BWWM12,
  title={Modeling and verifying the polarizing reflectance of real-world metallic surfaces},
  author={Berger, Kai and Weidlich, Andrea and Wilkie, Alexander and Magnor, Marcus},
  abstract={Using measurements of real-world samples of metals, the proposed approach verifies predictions of bidirectional reflectance distribution function (BRDF) models. It employs ellipsometry to verify both the actual polarizing effect and the overall reflectance behavior of the metallic surfaces.},
  journal={IEEE computer graphics and applications},
  volume={32},
  number={2},
  pages={24--33},
  year={2012},
  keywords={MINE,EN,journal,reviewed},
  url={https://www.cg.cs.tu-bs.de/upload/publications/cgaBerger.pdf},
  publisher={IEEE}
}

@article{LBM09,
  title={vIsage-A visualization and debugging framework for distributed system applications},
  author={Lipski, Christian and Berger, Kai and Magnor, Marcus},
  abstract={We present a Visualization, Simulation, And Graphical debugging Environment (vIsage) for distributed systems. Time-varying spatial data as well as other information from different sources can be displayed and superimposed in a single view at run-time. The main contribution of our framework is that it is not just a tool for visualizing the data, but it is a graphical interface for a simulation environment. Real world data can be recorded, played back or even synthesized. This enables testing and debugging of single components of complex distributed systems. Being the missing link between development, simulation and testing, e.g., in robotics applications, it was designed to significantly increase the efficiency of the software development process.},
  url={https://pdfs.semanticscholar.org/6a6b/a9c3c1f6979dc3bf59adfb7876b79f26b6be.pdf},
  year={2009},
  keywords={MINE,EN,conference,reviewed},
  publisher={V\'{a}clav Skala-UNION Agency}
}

@article{KABM10,
  title={Real-time gaze tracking with a consumer-grade video camera},
  author={Keil, Andrea and Albuquerque, Georgia and Berger, Kai and Magnor, Marcus},
  abstract={Eye gaze can be a rich source of information to identify particular interests of human users. Eye gaze tracking has been largely used in different research areas in the last years, as for example in psychology, visual system design and to leverage the user interaction with computer systems. In this paper, we present an IR-based gaze tracking framework that can be easily coupled to common user applications and allows for real-time gaze estimation. Compared to other gaze tracking systems, our system uses only affordable consumer-grade hardware and still achieves fair accuracy. To evaluate the usability of our gaze tracking system, we performed a user study with persons of different genders and ethnicities.},
  year={2010},
  keywords={MINE,EN,conference,reviewed},
  url={https://goo.gl/kNcZaS},
  publisher={V\'{a}clav Skala-UNION Agency}
}

@article{LBE+10,
  title={Sparse bundle adjustment speedup strategies},
  author={Lipski, Christian and Bose, Denis and Eisemann, Martin and Berger, Kai and Magnor, Marcus},
  abstract={Over the past years, Structure-from-Motion calibration algorithms have become widely popular for many applications in computer graphics. From an unordered set of photographs, they manage to robustly estimate intrinsic and extrinsic camera parameters for each image. One major drawback is the quadratic computation time of existing algorithms. This paper presents different strategies to overcome this problem by only working on subsets of images and merging the results. A quantitative comparison of these strategies reveals the trade-off between accuracy and computation time.},
  year={2010},
  keywords={MINE,EN,conference,reviewed},
  url={https://otik.uk.zcu.cz/bitstream/11025/11045/1/Lipski.pdf},
  publisher={V\'{a}clav Skala-UNION Agency}
}

@inproceedings{RLK+11,
  title={Integrating multiple depth sensors into the virtual video camera},
  author={Ruhl, Kai and Berger, Kai and Lipski, Christian and Klose, Felix and Schroeder, Yannic and Scholz, Alexander and Magnor, Marcus},
  booktitle={ACM SIGGRAPH 2011 Posters},
  abstract={In this ongoing work, we present our efforts to incorporate depth sensors into a multi camera system for free view-point video. Both the video cameras and the depth sensors are consumer grade. Our free-viewpoint system, the Virtual Video Camera, uses image-based rendering to create novel views between widely spaced (up to 15 degrees) cameras, using dense image correspondences. The introduction of multiple depth sensors into the system allows us to obtain approximate depth information for many pixels, thereby providing a valuable hint for estimating pixel correspondences between cameras.},
  pages={23},
  year={2011},
  url={https://graphics.tu-bs.de/upload/publications/kinectVVC.pdf},
  keywords={MINE,EN,conference,reviewed},
  organization={ACM}
}

@article{IBA+09,
  title={Tomographic reconstruction and efficient rendering of refractive gas flows},
  author={Ihrke, Ivo and Berger, Kai and Atcheson, Bradley and Magnor, Marcus and Heidrich, Wolfgang},
  abstract={This chapter introduces techniques for the capture and efficient display of dynamic three-dimensional non-stationary gas flows. We describe a flexible Schlieren-tomographic system consisting of multiple consumer camcorders. A special choice of background pattern for Background Oriented Schlieren (BOS) imaging provides for flexibility in the experimental setup. Optical flow techniques are used to measure image space deflections due to heated air flows from arbitrary camera positions. A specially tailored sparse-view algebraic reconstruction algorithm is employed to tomographically recover a refractive index gradient field. After robust integration of these gradient fields, time-varying, fully three-dimensional refractive index fields are obtained. These can be rendered efficiently using a ray-casting style algorithm that is suitable for graphics hardware acceleration. Additional optical properties can be rendered within the same computational framework.},
  journal={Imaging Measurement Methods for Flow Analysis},
  pages={145--154},
  year={2009},
  url={http://vccimaging.org/Publications/Ihrke2009TRE/Ihrke2009TRE.pdf},
  keywords={MINE,EN,bookchapter,reviewed},
  publisher={Springer Berlin/Heidelberg}
}

@article{BLL+10b,
  title={Target Space Modeling-The End of 3D Widgets},
  author={Berger, Kai and Linz, Christian and Lipski, Christian and Vaudrey, Tobi and Klette, Reinhard and Magnor, Marcus},
  year={2010},
  keywords={MINE,EN,conference,reviewed},
  publisher={V\'{a}clav Skala-UNION Agency}
}

@article{BWWM+12,
  title={Verifying and Modeling the Polarizing Reflectance of Real-World Metallic Surfaces},
  author={Berger, Kai and Weidlich, Andrea and Wilkie, Alexander and Magnor, Marcus},
  keywords={MINE,EN,techreport,reviewed},
  year={2012}
}

@inproceedings{BRMI11a,
  title={Refractive index dependent bidirectional scattering distribution functions},
  author={Berger, Kai and Reshetouski, Ilya and Magnor, Marcus and Ihrke, Ivo},
  booktitle={ACM SIGGRAPH 2011 Posters},
  pages={66},
  year={2011},
  keywords={MINE,EN,conference,reviewed},
  organization={ACM}
}

@inproceedings{BRMI11b,
  title={Measuring BRDFs of Immersed Materials},
  author={Berger, Kai and Reshetouski, Ilya and Magnor, Marcus A and Ihrke, Ivo},
  booktitle={VMV},
  pages={325--330},
  keywords={MINE,EN,conference,reviewed},
  year={2011}
}

@article{BLL+09,
  title={Echtzeiterkennung von befahrbaren Bereichen in urbanen Szenarien},
  author={Berger, Kai and Linz, Christian and Lipski, Christian and Stich, Timo and Magnor, Marcus},
  journal={Aktuelle Anwendungen in Technik und Wirtschaft},
  pages={1--10},
  year={2009},
  keywords={MINE,EN,conference,reviewed},
  publisher={Springer Berlin Heidelberg}
}

@article{BSGK13,
  title={Using sparse optical flow for multiple Kinect applications},
  author={Berger, Kai and Schroeder, Yannic and Guthe, Stefan and Kastner, Marc Aurel},
  year={2013},
  keywords={MINE,EN,conference,reviewed}
}

@inproceedings{CBA+13,
  title={SHREC'13 Track: Retrieval on Textured 3D Models},
  author={Cerri, Andrea and Biasotti, Silvia and Abdelrahman, Mostafa and Angulo, Jes\'{u}s and Berger, Kai and Chevallier, Louis and El-Melegy, Moumen T and Farag, Aly A and Lefebvre, Frederic and Giachetti, Andrea and others},
  booktitle={3DOR},
  pages={73--80},
  keywords={MINE,EN,conference,reviewed},
  year={2013}
}

@incollection{BMNK13,
  title={A state of the art report on kinect sensor setups in computer vision},
  author={Berger, Kai and Meister, Stephan and Nair, Rahul and Kondermann, Daniel},
  booktitle={Time-of-Flight and Depth Imaging. Sensors, Algorithms, and Applications},
  pages={257--272},
  year={2013},
  keywords={MINE,EN,bookchapter,reviewed},
  publisher={Springer Berlin Heidelberg}
}

@article{WBEC+14,
  title={Vehicle object retargeting from dynamic traffic videos for real-time visualisation},
  author={Walton, Simon and Berger, Kai and Ebert, David and Chen, Min},
  journal={The Visual Computer},
  volume={30},
  number={5},
  pages={493--505},
  year={2014},
  keywords={MINE,EN,journal,reviewed},
  publisher={Springer Berlin Heidelberg}
}

@article{Ber13a,
  title={The role of RGB-D benchmark datasets: an overview},
  author={Berger, Kai},
  keywords={MINE,EN,arxiv,reviewed},
  journal={arXiv preprint arXiv:1310.2053},
  year={2013}
}

@article{Ber13b,
  title={A State Of the Art Report on Research in Multiple RGB-D sensor Setups},
  author={Berger, Kai},
  keywords={MINE,EN,arxiv,reviewed},
  journal={arXiv preprint arXiv:1310.2050},
  year={2013}
}

@article{Ber14a,
  title={Real-time Pedestrian Surveillance with Top View Cumulative Grids},
  author={Berger, Kai and Thiyagalingam, Jeyarajan},
  keywords={MINE,EN,arxiv,reviewed},
  journal={arXiv preprint arXiv:1402.1359},
  year={2014}
}

@inproceedings{CWB+14,
  title={Visual multiplexing},
  author={Chen, Min and Walton, Simon and Berger, Kai and Thiyagalingam, Jeyarajan and Duffy, Brian and Fang, Hui and Holloway, Cameron and Trefethen, Anne E},
  booktitle={Computer Graphics Forum},
  keywords={MINE,EN,journal,reviewed},
  volume={33},
  number={3},
  pages={241--250},
  year={2014}
}

@article{WBT+14a,
  title={Visualising temporal cardiovascular imagery},
  author={Walton, Simon and Berger, Kai and Thiyagalingam, Jeyan and Chen, Min and others},
  journal={Progress in Biophysics and Molecular Biology},
  keywords={MINE,EN,journal,reviewed},
  year={2014}
}

@incollection{BKSG14,
  title={Using sparse optical flow for two-phase gas flow capturing with multiple kinect},
  author={Berger, Kai and Kastner, Marc and Schroeder, Yannic and Guthe, Stefan},
  booktitle={Computer Vision and Machine Learning with RGB-D Sensors},
  pages={157--169},
  year={2014},
  keywords={MINE,EN,conference,reviewed},
  publisher={Springer International Publishing}
}

@incollection{Ber14b,
  title={A state of the art report on multiple RGB-D sensor research and on publicly available RGB-D datasets},
  author={Berger, Kai},
  booktitle={Computer Vision and Machine Learning with RGB-D Sensors},
  pages={27--44},
  year={2014},
  keywords={MINE,EN,bookcahpter,reviewed},
  publisher={Springer International Publishing}
}

@article{WBT+14b,
  title={Visualizing cardiovascular magnetic resonance (CMR) imagery: challenges and opportunities},
  author={Walton, Simon and Berger, Kai and Thiyagalingam, Jeyarajan and Duffy, Brian and Fang, Hui and Holloway, Cameron and Trefethen, Anne E and Chen, Min},
  journal={Progress in biophysics and molecular biology},
  volume={115},
  number={2},
  pages={349--358},
  year={2014},
  keywords={MINE,EN,journal,reviewed},
  publisher={Pergamon}
}

@inproceedings{BRA+11,
  title={The capturing of turbulent gas flows using multiple kinects},
  author={Berger, Kai and Ruhl, Kai and Albers, Mark and Schr\"{o}der, Yannic and Scholz, Al and Kokem\"{u}ller, Jan and Guthe, Stefan and Magnor, M},
  booktitle={IEEE International Conference on Computer Vision Workshops (ICCV Workshops)},
  pages={1108--1113},
  year={2011},
  keywords={MINE,EN,conference,reviewed},
  organization={IEEE}
}

@phdthesis{Ber12,
  title={Measuring, Modeling and Verification of Light-matter Interaction Phenomena},
  author={Berger, Kai},
  keywords={MINE,EN,thesis,reviewed},
  year={2012}
}



@inproceedings{BHBM14,
  title={3d volume and velocity estimation. Application to PIV tomography},
  author={Barbu, Ioana and Herzet, C\'{e}dric and Berger, Kai and M\'{e}min, Etienne},
  keywords={MINE,EN,conference,reviewed},
  booktitle={Journ{\'e}e D5 Vannes},
  year={2014}
}

@inproceedings{BBC15,
  title={UHD image reconstruction by estimating interpolation error},
  author={Berger, Kai and Berger, Kongfeng and Le Callet, Patrick},
  booktitle={IEEE International Conference on Image Processing (ICIP)},
  pages={4743--4747},
  year={2015},
  keywords={MINE,EN,conference,reviewed},
  organization={IEEE}
}

@article{RBL+14,
  title={Caroline: An Autonomously Driving Vehicle for Urban Environments},
  author={Rauskolb, Fred W and Berger, Kai and Lipski, Christian and Magnor, Marcus and Cornelsen, Karsten and Effertz, Jan and Form, Thomas and Graefe, Fabian and Ohl, Sebastian and Schumacher, Walter and others},
  journal={arXiv preprint arXiv:1409.6584},
  keywords={MINE,EN,arxiv,reviewed},
  year={2014}
}

@incollection{RBL+09,
  title={Caroline: An autonomously driving vehicle for urban environments},
  author={Rauskolb, Fred W and Berger, Kai and Lipski, Christian and Magnor, Marcus and Cornelsen, Karsten and Effertz, Jan and Form, Thomas and Graefe, Fabian and Ohl, Sebastian and Schumacher, Walter and others},
  booktitle={The DARPA Urban Challenge},
  pages={441--508},
  year={2009},
  keywords={MINE,EN,bookchapter,reviewed},
  publisher={Springer Berlin Heidelberg}
}

@inproceedings{BVM17,
  title={Depth from stereo polarization in specular scenes for urban robotics},
  author={Berger, Kai and Voorhies, Randolph and Matthies, Larry H},
  booktitle={IEEE International Conference on Robotics and Automation (ICRA)},
  pages={1966--1973},
  year={2017},
  keywords={MINE,EN,conference,reviewed},
  organization={IEEE}
}

@inproceedings{BVM16,
  title={Incorporating polarization in stereo vision-based 3D perception of non-Lambertian scenes},
  author={Berger, Kai and Voorhies, Randolph and Matthies, Larry},
  booktitle={SPIE Defense+ Security},
  pages={98370P--98370P},
  year={2016},
  keywords={MINE,EN,conference,reviewed},
  organization={International Society for Optics and Photonics}
}







